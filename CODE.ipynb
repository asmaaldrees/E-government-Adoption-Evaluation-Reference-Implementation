{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Topic.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Guidelines.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the flowchart of the data analysis steps:\n",
    "\n",
    "<img src=\"Steps.png\" width=\"350\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install factor_analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pingouin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install semopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import math \n",
    "import semopy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "data0 = pd.read_csv('RawData.csv')\n",
    "data = data0.dropna()\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sum of Factors\n",
    "PEOU=pd.DataFrame(data[['PEOU1','PEOU2','PEOU3','PEOU4']]).sum(axis=1)\n",
    "PU=pd.DataFrame(data[['PU1','PU2','PU3','PU4']]).sum(axis=1)\n",
    "SI=pd.DataFrame(data[['SI1','SI2','SI3','SI4']]).sum(axis=1)\n",
    "FC=pd.DataFrame(data[['FC1','FC2','FC3','FC4']]).sum(axis=1)\n",
    "TOG=pd.DataFrame(data[['TOG1','TOG2','TOG3','TOG4']]).sum(axis=1)\n",
    "AB=pd.DataFrame(data[['ADOPT1','ADOPT2','ADOPT3','ADOPT4']]).sum(axis=1)\n",
    "dat1=pd.DataFrame([PEOU,PU,SI,FC,TOG,AB]).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Preliminary Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the required assessments for the preliminary analysis along with their threshold value:\n",
    "\n",
    "<img src=\"prelim.jpeg\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1- Missing Data Assssment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using dropna() function above, we dropped all raws with missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2- Reliability Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pingouin as pg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cronbach’s Alpha  for all factors\n",
    "pg.cronbach_alpha(data.iloc[:,5:28])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cronbach’s Alpha  for reliability of PEOU\n",
    "pg.cronbach_alpha(data=data[['PEOU1','PEOU2','PEOU3','PEOU4']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cronbach’s Alpha  for reliability of PU\n",
    "pg.cronbach_alpha(data=data[['PU1','PU2','PU3','PU4']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cronbach’s Alpha  for reliability of SI\n",
    "pg.cronbach_alpha(data=data[['SI1','SI2','SI3','SI4']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cronbach’s Alpha  for reliability of FC\n",
    "pg.cronbach_alpha(data=data[['FC1','FC2','FC3','FC4']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cronbach’s Alpha  for reliability of TOG\n",
    "pg.cronbach_alpha(data=data[['TOG1','TOG2','TOG3','TOG4']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cronbach’s Alpha  for reliability of AB\n",
    "pg.cronbach_alpha(data=data[['ADOPT1','ADOPT2','ADOPT3','ADOPT4']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3- Outliers Asssessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Covariance matrix\n",
    "dat21=data.iloc[:,4:28]\n",
    "dat2=pd.DataFrame(dat21)\n",
    "covariance  = np.cov(dat2 , rowvar=False)\n",
    "\n",
    "# Covariance matrix power of -1\n",
    "covariance_pm1 = np.linalg.matrix_power(covariance, -1)\n",
    "\n",
    "# Center point\n",
    "centerpoint = np.mean(dat2 , axis=0)\n",
    "p2=centerpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chi-Square is used to find cutoff value is, Mahalanobis Distance returns the distance as squared (D² )\n",
    "from scipy.stats import chi2\n",
    "from matplotlib import patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distances between center point of measurement items\n",
    "p2=centerpoint\n",
    "dat2 = dat2.to_numpy()\n",
    "distances=[]\n",
    "for i, val in enumerate(dat2):\n",
    "      p1 = val\n",
    "      p2= centerpoint\n",
    "      distance = (p1-p2).T.dot(covariance_pm1).dot(p1-p2)\n",
    "      distances.append(distance)\n",
    "distances = np.array(distances)\n",
    "\n",
    "# Cutoff (threshold) value from Chi-Sqaure Distribution for detecting outliers \n",
    "cutoff = chi2.ppf(0.999, dat2.shape[1]) \n",
    "chi2_value=cutoff ## Chi-square vale at alpha=0.001, 24(df)\n",
    "\n",
    "# Index of outliers\n",
    "outlierIndexes= np.where(distances>cutoff )\n",
    "print('Index of Outliers')\n",
    "print(outlierIndexes)\n",
    "print('Observations found as outlier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results shows that, no outlier exist in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2_value # for outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances #  for outlier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Dimensionality Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the required assessments for the dimenstionality analysis along with their threshold value:\n",
    "\n",
    "<img src=\"DimentionalityAssessment.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1- Data Adequacy Assesment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kaiser-Meyer-Olkin (KMO) Test measures the suitability of data for factor analysis.\n",
    "from factor_analyzer import FactorAnalyzer\n",
    "from factor_analyzer.factor_analyzer import calculate_kmo\n",
    "kmo_all,kmo_model=calculate_kmo(data)\n",
    "kmo_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bartlett’s test of sphericity checking\n",
    "from factor_analyzer.factor_analyzer import calculate_bartlett_sphericity\n",
    "chi_square_value,p_value=calculate_bartlett_sphericity(data)\n",
    "chi_square_value, p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2- Communality Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from factor_analyzer import FactorAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1=data.iloc[:,4:28]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fa=FactorAnalyzer(n_factors=6, rotation=\"varimax\")\n",
    "fa.fit(data1)\n",
    "loadings=fa.loadings_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get variance of each factors\n",
    "a=fa.get_factor_variance()\n",
    "pd.DataFrame.from_records(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## communalitie values\n",
    "fa.get_communalities()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3- Eigenvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Get the eigenvector and eigenvalues\n",
    "ev,v=fa.get_eigenvalues()\n",
    "# Scree plot\n",
    "xvals=range(1,data1.shape[1]+1)\n",
    "plt.scatter(xvals,ev)\n",
    "plt.plot(xvals,ev)\n",
    "plt.title('Scree Plot')\n",
    "plt.xlabel('Factors')\n",
    "plt.ylabel('Eigenvalues')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v  # Eigen-Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4- EFA Factor Loadings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loadings\n",
    "print(pd.DataFrame.from_records(loadings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Measurement Model Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1- GOF Indices for Measurement Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the required assessments for the GOF indices along with their threshold value:\n",
    "\n",
    "<img src=\"GOF.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from factor_analyzer import FactorAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## For  one-factor congeneric measurement for PEOU, PU,SI, FC, TOG, AB \n",
    "# Factor Analysis packages \n",
    "# To Run each factor, we will replace values in the following code \"data.iloc[]\"\"\n",
    "\n",
    "#data3=data.iloc[0:,4:8] # For PEOU\n",
    "#data3=data.iloc[0:,8:12] # For PU\n",
    "#data3=data.iloc[0:,12:16] # For SI\n",
    "#data3=data.iloc[0:,16:20] # For FC\n",
    "#data3=data.iloc[0:,20:24] # For TOG\n",
    "data3=data.iloc[0:,24:28] # For AB\n",
    "data3.shape\n",
    "fa1 = FactorAnalyzer(n_factors=1,rotation=None, rotation_kwargs={})\n",
    "fa1.fit(data3)\n",
    "loadings=-fa1.loadings_\n",
    "# Get variance of each factors\n",
    "a1=fa1.get_factor_variance()\n",
    "a1[0], loadings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from semopy import Model\n",
    "## # To Run each factor, we will repalace in the code on mode2 \n",
    "#mod2 = \"\"\" PEOU =~ PEOU1 + PEOU2 + PEOU3 + PEOU4 \"\"\"\n",
    "#mod2 = \"\"\" PU =~ PU1 + PU2 + PU3 + PU4 \"\"\"\n",
    "#mod2 = \"\"\" SI =~ SI1 + SI2 + SI3 + SI4 \"\"\"\n",
    "#mod2 = \"\"\" FC =~ FC1 + FC2 + FC3 + FC4 \"\"\"\n",
    "#mod2 = \"\"\" TOG=~ TOG1 + TOG2 + TOG3 + TOG4 \"\"\"\n",
    "mod2 = \"\"\" AB =~ ADOPT1 + ADOPT2 + ADOPT3 + ADOPT4 \"\"\"\n",
    "\n",
    "model2 = Model(mod2)\n",
    "model2.fit(data3)\n",
    "stats2 = semopy.calc_stats(model2)\n",
    "print(stats2.T)\n",
    "Results=model2.inspect(std_est=True)\n",
    "pd.set_option('display.max_rows', Results.shape[0]+1)\n",
    "print(Results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating SRMR \n",
    "data3=pd.DataFrame(data3)\n",
    "corr_Obs = np.corrcoef(data3 , rowvar=False)\n",
    "lod = np.dot(loadings, loadings.T)\n",
    "Corr_Exp = np.corrcoef(lod , rowvar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p is the number of items for the given factor\n",
    "p=4\n",
    "var=p*(p+1)/2\n",
    "SRMR=np.sqrt(np.mean((corr_Obs-Corr_Exp)**2)/var)\n",
    "print('SRMR value:', SRMR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ((We run the following part if the GOF values are not satisfactory, otherwise ignore it)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One factor Congeneric Measurement Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the required assessments for the one-factor congeneric analysis along with their threshold value:\n",
    "\n",
    "<img src=\"OneFactor.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A- Stndardized Factor Loading SFL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Results=model2.inspect(std_est=True)\n",
    "pd.set_option('display.max_rows', Results.shape[0]+1)\n",
    "print(Results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B- Stndardized Residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardized Residuals (SR)\n",
    "# the difference between both the observed and the estimated covariance.\n",
    "lod = np.dot(loadings, loadings.T)\n",
    "data3=pd.DataFrame(data3)\n",
    "covariance  = np.cov(data3 , rowvar=False)\n",
    "residuals =(covariance - lod)\n",
    "#covariance \n",
    "print(residuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## For  one-factor congeneric measurement for the given factor\n",
    "import graphviz\n",
    "\n",
    "semopy.semplot(model2,\"plot.jpeg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ((The end of the One factor Congeneric Measuremnt Model Analysis))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2- The Convergent Validity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the required assessments for the convergent validity analysis along with their threshold value:\n",
    "\n",
    "<img src=\"ConvergentValidity.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A- Stndardized Factor Loading SFL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Results=model2.inspect(std_est=True)\n",
    "pd.set_option('display.max_rows', Results.shape[0]+1)\n",
    "print(Results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B- Composite Reliability (CR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CR is are calculated via λ and E values.\n",
    "\n",
    "# λ values are the standardized factor loading of the four items to the corresponding factor.\n",
    "# E value is the respective error variance for item i.\n",
    "\n",
    "# The formula of CR is = (sum of λ values)^2 / [(sum of λ values)^2 + (sum of E values)]\n",
    "# The E value for each item is calculated as= 1- (λ value of that item)^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## CR for PEOU Factor\n",
    "lamda = (0.75+0.84+0.85+0.87)**2\n",
    "Evalue =0.44+0.29+0.28+0.24\n",
    "crPEOU = lamda/(lamda+Evalue)\n",
    "\n",
    "print('CR_PE0U:' ,crPEOU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CR for PU Factor\n",
    "lamda = (0.71+0.85+0.86+0.92)**2\n",
    "Evalue =0.50+0.28+0.26+0.15\n",
    "crPU = lamda/(lamda+Evalue)\n",
    "\n",
    "print('CR_PU:' ,crPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CR for SI Factor\n",
    "lamda = (0.77+0.89+0.85+0.91)**2\n",
    "Evalue=0.41+0.21+0.28+0.17\n",
    "crSI = lamda/(lamda+Evalue)\n",
    "\n",
    "print('CR_SI:' ,crSI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CR for FC Factor\n",
    "lamda = (0.77+0.88+0.84+0.92)**2\n",
    "Evalue=0.41+0.23+0.29+0.15\n",
    "crFC = lamda/(lamda+Evalue)\n",
    "\n",
    "print('CR_FC:' ,crFC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CR for TOG Factor\n",
    "lamda = (0.76+0.91+0.81+0.91)**2\n",
    "Evalue=0.42+0.17+0.34+0.17\n",
    "crTOG = lamda/(lamda+Evalue)\n",
    "\n",
    "print('CR_TOG:' ,crTOG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## AB Factor\n",
    "lamda = (0.82+0.85+0.81+0.90)**2\n",
    "Evalue=0.33+0.28+0.34+0.19\n",
    "crAB = lamda/(lamda+Evalue)\n",
    "\n",
    "print('CR_AB:' ,crAB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  C- Average Variance Extracted (AVE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AVE is are calculated via via λ and E values.\n",
    "\n",
    "# λ values are the standardized factor loading of the four items to the corresponding factor.\n",
    "# E value is the variance of the error term for each item.\n",
    "\n",
    "# The formula of AVE is = (the sum of squared λ values per each item) / [the sum of squared λ values per each item + (sum of E values)]\n",
    "# The E value for each item is calculated as= 1- (λ value of that item)^2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## AVE for PEOU Factor\n",
    "lamda=0.75**2+0.84**2+0.85**2+0.87**2\n",
    "Evalue =0.44+0.29+0.28+0.24\n",
    "avePEOU = lamda/(lamda+Evalue)\n",
    "\n",
    "print('AVE_PEOU:',avePEOU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## AVE for PU Factor\n",
    "lamda=0.71**2+0.85**2+0.86**2+0.92**2\n",
    "Evalue =0.50+0.28+0.26+0.15\n",
    "avePU = lamda/(lamda+Evalue)\n",
    "\n",
    "print('AVE_PU:',avePU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## AVE for SI Factor\n",
    "lamda=0.77**2+0.89**2+0.85**2+0.91**2\n",
    "Evalue=0.41+0.21+0.28+0.17\n",
    "aveSI = lamda/(lamda+Evalue)\n",
    "\n",
    "print('AVE_SI:',aveSI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## AVE for FC Factor\n",
    "lamda=0.77**2+0.88**2+0.84**2+0.92**2\n",
    "Evalue=0.41+0.23+0.29+0.15\n",
    "aveFC = lamda/(lamda+Evalue)\n",
    "\n",
    "print('AVE_FC:',aveFC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## AVE for TOG Factor\n",
    "lamda=0.76**2+0.91**2+0.81**2+0.91**2\n",
    "Evalue=0.42+0.17+0.34+0.17\n",
    "aveTOG = lamda/(lamda+Evalue)\n",
    "\n",
    "print('AVE_TOG:',aveTOG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## AVE for AB Factor\n",
    "lamda=0.82**2+0.85**2+0.81**2+0.90**2\n",
    "Evalue=0.33+0.28+0.34+0.19\n",
    "aveAB = lamda/(lamda+Evalue)\n",
    "\n",
    "print('AVE_AB:',aveAB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3- The Discriminant Validity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The required assessment for the discriminant validity is caculated by the square root of AVE for each independent factor. \n",
    "\n",
    "The square root of AVE of each factor should be greater than its correlation with other factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the square root of AVE for each independent factor.\n",
    "print('Discriminant validity of PEOU factor:',np.sqrt(avePEOU))\n",
    "print('Discriminant validity of PU factor:',np.sqrt(avePU))\n",
    "print('Discriminant validity of SI factor:',np.sqrt(aveSI))\n",
    "print('Discriminant validity of FC factor:',np.sqrt(aveFC))\n",
    "print('Discriminant validity of TOG factor:',np.sqrt(aveTOG))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Structural Model Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1- GOF Indices for Structural Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same GOF indices are calculated for the structural model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semopy import Model\n",
    "mod = \"\"\" PEOU =~ PEOU1 + PEOU2 + PEOU3+PEOU4\n",
    "PU =~ PU1 + PU2 + PU3 + PU4\n",
    "SI =~ SI1+ SI2 + SI3+ SI4\n",
    "FC =~ FC1+ FC2 + FC3+ FC4\n",
    "TOG =~ TOG1+ TOG2 + TOG3+ TOG4\n",
    "AB =~ADOPT1+ADOPT2+ADOPT3+ADOPT4\n",
    "# regressions\n",
    "AB~PEOU\n",
    "AB~PU\n",
    "AB~SI\n",
    "AB~FC\n",
    "AB~TOG \"\"\"\n",
    "model = Model(mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stats = semopy.calc_stats(model)\n",
    "print(stats.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating SRMR \n",
    "from factor_analyzer import FactorAnalyzer\n",
    "\n",
    "data1=data.iloc[0:,4:28]\n",
    "fa2=FactorAnalyzer(n_factors=6, rotation=\"varimax\")\n",
    "fa2.fit(data1)\n",
    "loadings=fa2.loadings_\n",
    "corr_Obs = np.corrcoef(data1 , rowvar=False)\n",
    "lod = np.dot(loadings, loadings.T)\n",
    "Corr_Exp = np.corrcoef(lod , rowvar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p is the number of items/variables for the whole structural model\n",
    "p=24\n",
    "var=p*(p+1)/2\n",
    "SRMR=np.sqrt(np.mean((corr_Obs-Corr_Exp)**2)/var)\n",
    "print('SRMR value:', SRMR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2- Path Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the required assessments for the path analysis along with their threshold value:\n",
    "\n",
    "<img src=\"pathAnalysis.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insp=model.inspect(std_est=True)\n",
    "\n",
    "pd.set_option('display.max_rows', insp.shape[0]+1)\n",
    "print(insp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "\n",
    "semopy.semplot(model,\"plot_Data.jpeg\", plot_exos=False, plot_covs=True,engine=\"neato\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "semopy.semplot(model,\"plot.jpeg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ////// Extended Code for the Demogrphic Data //////"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A. Path Analysis per Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "data0 = pd.read_csv('RawData.csv')\n",
    "data = data0.dropna()\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model 1: For Male only\n",
    "data = data[data[\"Gender\"]==1]\n",
    "###################################\n",
    "# Model 2: For Female only\n",
    "#data = data[data[\"Gender\"]==2]\n",
    "######################################\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# measurement model\n",
    "# The first step\n",
    "from semopy import Model\n",
    "mod = \"\"\" PEOU =~ PEOU1 + PEOU2 + PEOU3+PEOU4\n",
    "PU =~ PU1 + PU2 + PU3 + PU4\n",
    "SI =~ SI1+ SI2 + SI3+ SI4\n",
    "FC =~ FC1+ FC2 + FC3+ FC4\n",
    "TOG =~ TOG1+ TOG2 + TOG3+ TOG4\n",
    "AB =~ADOPT1+ADOPT2+ADOPT3+ADOPT4\n",
    "# regressions\n",
    "AB~PEOU\n",
    "AB~PU\n",
    "AB~SI\n",
    "AB~FC\n",
    "AB~TOG \"\"\"\n",
    "model = Model(mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(data)\n",
    "#\n",
    "insp=model.inspect(std_est=True)\n",
    "pd.set_option('display.max_rows', insp.shape[0]+1)\n",
    "print(insp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "semopy.semplot(model,\"plot_GenderData.jpeg\", plot_exos=False, plot_covs=True,engine=\"neato\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "semopy.semplot(model,\"Genderplot.jpeg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B.  Path Analysis per Education Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "data0 = pd.read_csv('RawData.csv')\n",
    "data = data0.dropna()\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model 1: For Education evel: No formal school\n",
    "#data = data[data[\"Education Level\"]==1]\n",
    "##################################\n",
    "#Model 2: For Education evel: High school or less \n",
    "#data = data[data[\"Education Level\"]==2]\n",
    "##################################\n",
    "#Model 3: For Education evel: Associate degree\n",
    "#data = data[data[\"Education Level\"]==3]\n",
    "###################################\n",
    "# Model 4: For Undergraduate degree\n",
    "data = data[data[\"Education Level\"]==4]\n",
    "######################################\n",
    "# Model 5: For Graduate degree\n",
    "#data = data[data[\"Education Level\"]==5]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# measurement model\n",
    "# The first step\n",
    "from semopy import Model\n",
    "mod = \"\"\" PEOU =~ PEOU1 + PEOU2 + PEOU3+PEOU4\n",
    "PU =~ PU1 + PU2 + PU3 + PU4\n",
    "SI =~ SI1+ SI2 + SI3+ SI4\n",
    "FC =~ FC1+ FC2 + FC3+ FC4\n",
    "TOG =~ TOG1+ TOG2 + TOG3+ TOG4\n",
    "AB =~ADOPT1+ADOPT2+ADOPT3+ADOPT4\n",
    "# regressions\n",
    "AB~PEOU\n",
    "AB~PU\n",
    "AB~SI\n",
    "AB~FC\n",
    "AB~TOG \"\"\"\n",
    "model = Model(mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(data)\n",
    "#\n",
    "insp=model.inspect(std_est=True)\n",
    "pd.set_option('display.max_rows', insp.shape[0]+1)\n",
    "print(insp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "semopy.semplot(model,\"plot_EducationLevelData.jpeg\", plot_exos=False, plot_covs=True,engine=\"neato\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "semopy.semplot(model,\"Educationplot.jpeg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C.  Path Analysis per Age group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "data0 = pd.read_csv('RawData.csv')\n",
    "data = data0.dropna()\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model 1: For Age group: 18-30 years old\n",
    "#data = data[data[\"Age Group\"]==1]\n",
    "##################################\n",
    "#Model 2: For Age group: 31-40 years old\n",
    "#data = data[data[\"Age Group\"]==2]\n",
    "###################################\n",
    "# Model 3: For Age group: 41-50 years old\n",
    "#data = data[data[\"Age Group\"]==3]\n",
    "######################################\n",
    "# Model 4: For Age group: 51-60 years old\n",
    "data = data[data[\"Age Group\"]==4]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# measurement model\n",
    "# The first step\n",
    "from semopy import Model\n",
    "mod = \"\"\" PEOU =~ PEOU1 + PEOU2 + PEOU3+PEOU4\n",
    "PU =~ PU1 + PU2 + PU3 + PU4\n",
    "SI =~ SI1+ SI2 + SI3+ SI4\n",
    "FC =~ FC1+ FC2 + FC3+ FC4\n",
    "TOG =~ TOG1+ TOG2 + TOG3+ TOG4\n",
    "AB =~ADOPT1+ADOPT2+ADOPT3+ADOPT4\n",
    "# regressions\n",
    "AB~PEOU\n",
    "AB~PU\n",
    "AB~SI\n",
    "AB~FC\n",
    "AB~TOG \"\"\"\n",
    "model = Model(mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(data)\n",
    "#\n",
    "insp=model.inspect(std_est=True)\n",
    "pd.set_option('display.max_rows', insp.shape[0]+1)\n",
    "print(insp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "semopy.semplot(model,\"AgeData.jpeg\", plot_exos=False, plot_covs=True,engine=\"neato\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "semopy.semplot(model,\"Ageplot.jpeg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
